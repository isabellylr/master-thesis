% !TEX root = ../thesis.tex

\chapter{Introduction}
\label{sec:intro}

Many human reasoning tasks have been adequately modelled by a computational approach based on the weak completion semantics. In most of the cases, the models generated by this approach rely on the sceptical abductive consequences of an observation and the least model of a logic program representing the given background knowledge. This approach has been encoded as a connectionist network which is going to be the focus of this thesis. In this chapter, we show some of the mentioned reasoning problems as well as an overview of this network's architecture. 

\section{Sceptical Abduction}

The notion of abduction was first introduced by the philosopher Pierce \cite{quine1933collected}. Let us illustrate the idea of abduction by means of an example. Consider a background knowledge consisting of the following conditionals:
\[
\begin{array}{l}
\mbox{\textit{If it rained last night, then the grass is wet.}}\\
\mbox{\textit{If the sprinkler was on, then the grass is wet.}}\\
\mbox{\textit{If the grass is wet, then the shoes are wet.}}\\
\end{array}
\]
If we observe that the shoes are wet, we have several explanations. One explanation is that the grass is wet. However, we can further explain, why the grass is wet. Then, we obtain the explanation \textit{it rained last night} and the explanation \textit{the sprinkler was on}. The last two explanations are called basic, since we cannot further explain them. Another explanation is \textit{the sprinkler was on and it rained last night}, which combines the last two explanations. Then, this explanation is not minimal. One meaningless explanation is \textit{the shoes are wet}, i.e. the observation is explained by itself.

There are two forms of abduction which are well known in the literature: credulous and sceptical abduction. In credulous abduction, considering a specific background knowledge, humans would derive a conclusion if it follows from at least one of the explanations for the given observation. On the other hand, this is not sufficient in sceptical abduction where all explanations shall be considered. Coming back to the example, if we observe that \textit{the grass is wet}, then we could credulously conclude that \textit{it rained last night}. However, in the scenario where \textit{the sprinkler was on}, our observation is also explained and not necessarily \textit{it rained last night} has to be true. Therefore, we can neither sceptically conclude that \textit{it rained last night} nor that \textit{the sprinkler was on}.

As we will discuss in more details later on, psychological experiments have shown that humans systematically deviate from the classical logically correct answers. Therefore, we will consider a non-classical approach to model human reasoning which is non-monotonic and based on the least model of the weak completion of logic programs. More precisely, here we focus focus on the component of this framework responsible for deciding which and in what order possible explanations should be considered.

\subsection{Byrne's Suppression Task}

A well-known psychological experiment by Byrne \cite{byrne1989suppressing} has shown that, in certain circumstances, participants reject instances of the valid \textit{modus ponens} and \textit{modus tollens} inference form in conditional arguments. This experiment shows that people might suppress previously drawn conclusions when additional information becomes available. For example, when a conditional premise, such as \textit{if she has an essay to finish, then she will study late in the library} is accompanied by the fact \textit{she has an essay to finish}, 96\% of the participants conclude that \textit{she will study late in the library}. However, if we add the conditional premise \textit{if the library stays open, she will study late in the library}, then the number of participants which conclude that \textit{she will study late in the library} drops to 38\%.

This experiment is a strong support for the assumption that humans reason non-monotonically. In the complete experiment, participants receive the following three conditionals:
\[
\begin{array}{ll}
\mbox{\textbf{Simple}} & \mbox{\textit{If she has an essay to finish, then she will study late in the library}}.\\
\mbox{\textbf{Alternative}} & \mbox{\textit{If she has a textbook to read, then she will study late in the library}}.\\
\mbox{\textbf{Additional}} & \mbox{\textit{If the library stays open, then she will study late in the library}}.
\end{array}
\]

The participants were divided into three groups such that each group received a different combination of these conditionals:
\[
\begin{array}{ll}
\mbox{\textbf{Group I}} & \mbox{Simple}.\\
\mbox{\textbf{Group II}} & \mbox{Simple + Alternative}.\\
\mbox{\textbf{Group III}} & \mbox{Simple + Additional}.
\end{array}
\]

The task given to the participants consisted of two parts. In the first part the participants got either the fact \textit{she has an essay to finish} ($e^\top$) or the negation of it, \textit{she does not have an essay to finish} ($e^\bot$). In the second part the participants got either the fact \textit{she will study late in the library} ($l^\top$) or the negation of it, \textit{she will not study late in the library} ($l^\bot$). Based on the given information, the participants were asked to draw conclusions.

\begin{table}
\centering
\begin{tabular}{ccccc}
Fact & Conclusion & Group I & Group II & Group III\\
\hline
\hfill	\\		
$e^\top$ & $l^\top$ & 96\% & 96\% & \textbf{38\%}\\
$e^\bot$ & $l^\bot$ & 46\% & \textbf{4\%}   & 63\%\\
$l^\top$ & $e^\top$ & 53\% & \textbf{16\%} & 55\%\\
$l^\bot$ & $e^\bot$ & 69\%  & 69\% & \textbf{44\%}
\end{tabular}
\bigskip
\caption{Empirical results about suppression obtained by Byrne.}
\label{table:suppresion}
\end{table}

An overview of the empirical results obtained from this experiment is shown in Table~\ref{table:suppresion}. Percentages indicate the proportion of participants in each of the three groups that have drawn the respective conclusion from the indicated given fact and the conditionals. Where suppression took effect, the propositions are highlighted in bold. Similar results have been obtained by other researchers, see for example~\cite{dieussaert2000strategies}.

The suppression task is adequately modelled by the weak completion semantics using skeptical abduction. In particular, consider the case where we observe that \textit{she will study late in the library} is true. If we model only the conditional given to Group I, the consequence that \textit{she has an essay to finish} is derived, while if we model the conditionals given to Group II, this is no longer the case. If we observe the psychological results, our approach is able to suppress the conclusion when one more conditional to the background knowledge is added, reflecting the answers given by the participants.

\subsection{Wason's Selection Task}

In the original selection task \cite{wason1968reasoning} participants were told that each card had a letter on one side of the card and a number on the other side of the card. They were presented the following four cards the table:
\[
\framebox(50,55){D}  \quad\quad\quad \framebox(50,55){F}  \quad\quad\quad
\framebox(50,55){3}  \quad\quad\quad \framebox(50,55){7} 
\]
The task of the participants was to evaluate the following conditional with respect to each of the four cards:
\[
\mbox{\textit{if there is a D on one side of the card, then there is 3 on the other side.}}
\]
Which cards must be turned over in order to find out whether the conditional holds?

Assume the conditional is represented in classical propositional logic by the implication 
\[
3 \leftarrow D
\]
where the propositional variable \textit{3} represents the fact that the number 3 is shown and \textit{D} represents the fact that the letter D is shown. Then, in order to verify  the implication one must turn the cards showing D and 7. However, as repeated experiments have shown consistently (see Table~\ref{table:abstract}), participants believe differently. 

Whereas 89\% of the participants correctly determine that the card showing D must be turned (a number other than 3 on the other side would falsify the implication), 62\% of the participants incorrectly suggests turning the card showing 3 (no relevant information can be found which would falsify the implication). Likewise, whereas only 25\% of the participants correctly believe that the card showing 7 need to be turned (if the other side would show a D, then the implication is falsified), 16\% incorrectly believe that the card showing F needs to be turned (no relevant information can be found which would falsify the implication). In other words, the overall correctness of the answers for the abstract selection task if modelled by an implication in classical two-valued logic is pretty bad.

The selection task was adapted to a social case \cite{griggs1982elusive}. Consider the following four cards:
\[
\framebox(50,55){beer}  \quad\quad\quad \framebox(50,55){coke}  \quad\quad\quad 
\framebox(50,55){22 years} \quad\quad\quad  \framebox(50,55){16 years} 
\]

Each card has the person's age on one side of the card and what the person is drinking on the other side of the card. Consider the conditional
\[
\mbox{\textit{if a person is drinking beer, then the person must be over 19 years of age.}}
\]
The same question is then asked: Which cards must be turned over in order to find out whether the conditional holds?

If the conditional is represented by the implication 
\[
over19 \leftarrow beer,
\]
where $over19$ represents a person being older than 19 years and \textit{beer} represents the person drinking beer. In order to verify the implication, one must turn the cards drinking beer and 16 years old. Participants usually solve the social version of the selection task classical logically correctly. Table~\ref{table:social} shows the results represented by Griggs and Cox \cite{cox1982effects} for the social case. 

\begin{table}
	\centering
	\begin{subtable}[h]{0.30\textwidth}
		\begin{tabular}{cccc}
			D & F & 3 & 7 \\
			\hline
			89\% & 16\% & 62\% & 25\%
		\end{tabular}
		\bigskip
		\caption{Abstract case.}
		\label{table:abstract}
	\end{subtable}
	\hspace{2cm}
	\begin{subtable}[h]{0.30\textwidth}
		\begin{tabular}{cccc}
			beer & coke & 22yrs& 16yrs\\
			\hline
			95\% & 0.025\% & 0.025\% & 80\%
		\end{tabular}
		\bigskip
		\caption{Social case.}
		\label{table:social}
	\end{subtable}
	\hspace{1cm}
	\bigskip
	\caption{The results of the abstract (a) and social (b) cases of the selection task.}
\end{table}

One explanation for the differences between both cases can be found in \cite{kowalski2011computational}, namely that people view the conditional in the abstract case as a belief. For instance, the participants perceive the task to examine whether the rule is either \textit{true} or \textit{false}. On the other hand, in the social case, the participants perceive the rule as a social constraint, a conditional that ought to be \textit{true}. People intuitively aim at preventing the violation of such a constraint, which is normally done by observing whether the state of the world complies with the rule.

Both abstract and social cases can be modelled by an approach based on the weak completion semantics shown in \cite{dietz2013computational}. The fact that two conditionals following the same syntactic structure were evaluated differently gives a strong intuition that the semantics is also an important criteria to be considered when modelling those reasoning tasks. In the next section the discussion on the semantics of conditionals is developed in more details.

\subsection{Conditionals Semantics}

Conditionals can be categorised in many different types and classes, but there are two main groups of conditionals: indicative and subjunctive conditionals, the latter of which are also known as counterfactuals. In indicative conditionals both, the condition and the consequence, can be either true, false or unknown. But if the condition is true, then the consequence is asserted to be true. In counterfactuals, the consequence can again be either true, false or unknown, but the condition is known to be false. Besides that, in the couterfactual circumstance of the condition being true, the consequence is asserted to be true.

In we focus on indicative conditionals, there are many subclasses to be considered. For example, they can be classified into \textit{obligation} and \textit{factual conditionals}. The difference between them is that in the \textit{obligation conditionals} the consequence is obligatory, while in the \textit{factual conditionals} this is not  the case. More precisely, given an \textit{obligation conditionals} it can never be the case that the condition happens and the consequence doesn't.

As explained in \cite{byrne2007rational}, conditionals where the consequent is denied are more likely to be evaluated to \textit{true} if it is an \textit{obligation conditional}. This happens because for this type of conditionals, people keep in mind a forbidden possibility where condition and not consequence happens together and, in this case, if not consequence is  known to be \textit{true}, then it cannot be the case that condition is \textit{true} as well, otherwise the forbidden possibility is violated. Thus, \textit{not condition} is concluded.  But, since in a \textit{factual conditional} this forbidden possibility does not exist, conditionals with the consequence denied should be evaluated to \textit{unknown}. 

Consider the following conditional:
\[
\begin{array}{c}
\mbox{\textit{If it rains, then the streets are wet.}}
\end{array}
\]
Its consequence is obligatory. We cannot easily imagine a case where the condition the \textit{it rains} is true and the consequence \textit{the streets are wet} is not. We know streets, we know rain and its effects, and because the conditional is discussed without any specific context, there does not appear to be a case where the condition is true and the consequence is not. But if we now consider the following conditional:
\[
\begin{array}{c}
\mbox{\textit{If it rains, then she takes her umbrella.}}
\end{array}
\]
Is consequence is not obligatory. Different than in the previous case, is the condition \textit{it rains} is true, we can easily think about a scenario where the consequence \textit{she takes her umbrella} is not. It is not so counterintuitive to imagine that it rained and she forgot to take her umbrella, for example.

In the selection task, the conditional considered in the abstract case is classified as a \textit{factual conditional} as there is no obligation implied from the context. On the other hand, the conditional considered in the social case is classified as an \textit{obligation conditional} as there is a clear obligation implied from the \textit{must} condition. There are also semantic differences in the conditions of these conditionals which are discussed in \cite{saldanhaobligation}.

\subsection{Syllogistic Reasoning}

A syllogism consists of two premises and a conclusion. Each of them is a quantified statement using one of the four quantifiers \textit{all}, \textit{no}, \textit{some}, and \textit{some are not} over sets of entities which we denote in the following by a, b, and c. An example of a syllogism is:
\[
\begin{array}{l}
\mbox{\textit{Some b are a}}\\
\mbox{\textit{No b are c}}
\end{array}
\]

In experiments, participants are normally expected to complete the syllogism by drawing a logical consequence from the first two premises, e.g. in this example \textit{some a are not c}. Altogether, there are 64 syllogisms and, if formalised in first-order logic, we can compute their logical consequence in classical logic. The first two premises together with a consequence that follows classical logically is called a \textit{valid syllogism}. Otherwise, it is called an \textit{invalid syllogism}.

A meta-analysis by Khemlani and Johnson Laird \cite{khemlani2012theories} based on six experiments has shown that humans do not only deviate from the classical predictions of first-order logic, but from any other of at least twelve cognitive theories on the syllogistic reasoning. To understand the deviation from classical logic on the experimental results, let us consider an example of a syllogism discussed by Evans \cite{evans2013reasoning} which has an invalid but believable conclusion as well as a valid but unbelievable conclusion. Given the following two premises:
\[
\begin{array}{l}
\mbox{\textit{No addictive things are inexpensive.}}\\
\mbox{\textit{Some cigarettes are inexpensive.}}
\end{array}
\]
The conclusion that \textit{some addictive things are inexpensive} is invalid, but believable. On the other hand, the conclusion that \textit{some cigarettes are not addictive} is valid, but unbelievable.

From the cognitive theories available in the literature, the best overall results are achieved by Polk and Newell, the Verbal Models Theory \cite{polk1995deduction}, which predicts 84\% of the participants responses, closely followed by Johnson-Laird, the Mental Model Theory \cite{johnson1983mental}, with 83\%, whereas PSYCOP \cite{rips1994psychology} by Rips only predicts 77\% of the participants' responses. 

Recently, a new cognitive theory, based on the weak completion semantics and skeptical abduction, to model the syllogistic reasoning task has been developed by Costa, Dietz, H{\"o}lldobler and Ragni \cite{da2017computational}. This approach identifies seven principles, mostly motivated from findings in cognitive science, which are necessary to draw the inferences. This approach has achieved the best results, compared to the results of other cognitive theories, with a prediction of 89\%.

\section{A Core Method for Sceptical Abduction}

H{\"o}lldobler and Kencana Ramli \cite{holldobler2009logics} have shown that the computation of the least fixed point of the $\Phi_\CalP$ operator can be realised within a connectionist network, with the core-method \cite{bader2006core}. A connectionist realisation of sceptical abduction under the weak completion semantics within the core method has been showed by Dietz Saldanha, H{\"o}lldobler, Kencana Ramli, and Palacios Medinacelli \cite{corepaper}. Figure~\ref{fig:coreoverview} shows an overview of this connectionist network which consists of three main components.

\begin{figure}[h]
\begin{center}
\scalebox{0.9}{\coreoverview}
\end{center}
\caption{Overall view of the connectionist network to compute the sceptical consequences of a given abductive problem.}
\label{fig:coreoverview}
\end{figure}

The first component of the network $\CalN_{\CalA_\CalP}$ sequentially generates the candidate explanations to be considered by the abductive framework one after the other and only upon request. The second component $e\CalN_{\CalA_\CalP}$ computes the least model of the weak completion of $\CalP \cup \CalC$, where $\CalP$ is the program considered as background knowledge and $\CalC$ is the current candidate explanation generated by $\CalN_{\CalA_\CalP}$. The network $e\CalN_{\CalA_\CalP}$ sends the request of a new candidate to network $\CalN_{\CalA_\CalP}$ once its task is done.

Besides the next candidate explanation, the network $\CalN_{\CalA_\CalP}$ also outputs the information whether the candidate generated is the last one. When that's the case, after the computation of the least model of this last candidate to be considered, the network $\CalN_\CalS$ computes all the sceptical consequences of the given observation by merging all the consequences followed by the program and the positive candidates.

The complexity of the task corresponding to component $\CalN_{\CalA_\CalP}$ is exponential with respect to the cardinality of the set of abducibles. The computation of the least fixed point of $\Phi_\CalP$, corresponding to component $e\CalN_{\CalA_\CalP}$, can be done in polynomial time as shown by Dietz Saldanha, H{\"o}lldobler, and Philipp \cite{saldanha1872contextual}. The remaining component, denoted by $\CalN_\CalS$, has the task of computing the sceptical consequences, given the consequences of each positive candidate. This can be done by intersecting the given consequences, which can be reduced to the problem of sets intersection. Therefore, it can also be done in polynomial time.

Based on the complexity of each of those tasks, it is clear that the bottleneck of the problem is in the generation of candidate explanations. This component is encoded by means of a McCulloch Pitts network designed to generate all the non-complementary candidate explanations in a static and pre-defined order. The complexity results of the way we apply sceptical abduction is a strong indication that humans do not reason in the same way. 

Motivated by this, we believe that humans do not generate all candidate explanation but rather a subset of them. Therefore, we are going to make some assumptions in the reasoning process which will allow us to reduce the number of generated candidate explanations. However, as there are so many open questions regarding this problem which have not yet been verified, we also propose to substitute the current approach by a more flexible one which is able to learn arbitrary sequences of candidate explanations and, therefore, can easily be adapted to the constraints later identified in psychological experiments.

\section{Hypotheses}

In order to optimise the process of generating candidate explanations and align it with the real cognitive process regarding sceptical abduction, we are going to make some assumptions as, for example, regarding minimal and bounded candidates. In this section we will discuss these hypotheses and their implications in more details.

\subsection{Basic Candidate Explanations}

Reconsidering the first example presented in Section~1.1, the only possible explanations which would be considered in our approach for the observation \textit{the shoes are wet} are concerning that \textit{it rained last night} or that \textit{the sprinkler was on}, but not that the \textit{the grass is wet}. This is a consequence of the abductive framework where we only consider the undefined atoms in the set of abducibles which are later going to be used for the generation of candidate explanations. 

Therefore, our first hypothesis is that when humans reason about the sceptical consequences of a given problem they search for the basic candidate explanations and reason only with respect to them. An explanation is said to be basic if it cannot be explained by other facts or assumptions, i.e. it can only be explained by itself.

\subsection{Sequential Generation}

The second hypothesis we make is that humans do not generate several candidate explanations in parallel but they are sequentially generated and considered one by one in the reasoning process. Therefore, we do not have a distributed approach. Instead, the candidate explanations are generated after the other. Besides, a new candidate is generated only after our approach checks whether the current candidate is indeed an explanation for the given observation.

\subsection{Non-complementary Candidate Explanations}

Consider the following conditional: 
\[
\begin{array}{l}
\mbox{\textit{If she studies, then she will pass the exam.}}\\
\end{array}
\]
To explain, for instance, the observation that \textit{she did not pass the exam}, we would not consider as candidate explanation the facts that \textit{she studied} and that \textit{she did not study} together. This type of candidate explanations are said to be complementary. Therefore, in our approach we also have the hypothesis that humans only consider non-complementary candidate explanations.

\subsection{Minimal Candidate Explanations}

Another hypothesis is that humans generate only minimal candidate explanations. If we reconsider Byrne's selection task presented earlier, for the observation that \textit{she studies late in the library}, the minimal explanations would be either that \textit{she has an essay to finish} or that \textit{she has a text book to read}. The case where both explanations are combined also explains the given observation, but in a non-minimal way and, therefore, should not be considered. Moreover, the cases where \textit{she has an essay to finish} but \textit{she does not have a text book to read} and the other way around are also non-minimal explanations for the observation.

This hypothesis implies a constraint in the generation of the candidate explanations which is about the cardinality of the candidates. It is easy to see that if the candidate where \textit{she has an essay to finish} and \textit{she has a text book to read} are both true is generated before a candidate where only one of these two facts is true and the other one is unknown, then there is no way to avoid this non-minimal candidate as it's subset is not known yet. Given this observation, we assume the generation of candidates has to be done from the smaller to the larger sets of candidates, where smaller and bigger is defined by their cardinality. 

\subsection{Bounded Sceptical Abduction}

Although the minimality constraint reduces the number of candidate explanations generated in average, the complexity of the problem remains the same in the worse case. Imagine a ordering respecting the cardinality where the explanation \textit{she does not have an essay to finish} and \textit{she does not have a text book to read} is the last one. If we observe that \textit{she does not study late in the library}, the only possible explanation for our observation would be the last one, which means that all the candidates would have to be generated just as before.

As mentioned before, it is hard to believe that humans would systematically generate all the candidate explanation to solve such a problem. Therefore, we have the hypothesis that there is a bound in the generation of candidate explanation and that the reasoning process is different for different types of conditionals as it has been investigated in \cite{saldanhaobligation}. This implies that arbitrary sequences of candidate explanations have to be considered.

\section{Tasks}

Considering the hypotheses we have made, we will now show what has to be done in the current approach to achieve such results. The tasks consist of two steps: first, we will show how to apply the minimality characterisation to the current McCulloch Pitts network, and, after this, we show a formal specification on how to substitute this component by a recurrent network which can learn arbitrary sequences of candidates.

\subsection{Minimality}

Given that the McCulloch Pitts network generates the candidate explanations in a static and pre-defined order, we can easily consider a sequence which respects the cardinality ordering. Given that the candidates are being generated from the smaller to the larger ones, we can store the information of which candidates were positive and use this information to block the generation of further candidates which are supersets of them. 

This can be done by adding a unit to the network corresponding to each of the candidates with cardinality larger than one. These units will be connected to all the units representing subsets of the respective candidate such that they are activated as soon as one of these candidates has been detected as being an explanation. The activation of these units will be stored for the further time steps and used later on to skip the generation of the non-minimal candidates. By this thechnique we ensure that only minimal candidate explanations are generated.

\subsection{Arbitrary Sequences}

In order to confirm our hypothesis on the bounded candidates and try to obtain more properties in the arbitrary sequence of candidates, we design some psychological experiments and propose their execution. Considering that there are so many open questions concerning this problem and that the psychological results are crucial to obtain a strong cognitive theory, we propose the substitution of the current approach by a recurrent network which can learn arbitrary sequences of candidate explanations and, therefore, easily adapt to the outcome of these experiments independent on what they are.

For this purpose, we will focus on Jordan and Elman networks and provide a formal specification on how they can be constructed, trained and tested for the problem of generating candidate explanations. This process evolves transforming our problem in a temporal domain problem and generating data which simulates the candidate explanations expected in different scenarios. We will start by showing that they can achieve the same results presented by the previous approach, but with the advantage of learning arbitrary sequences. We will design experiments to define the necessary number of hidden units such that they perform the task with a error rate close to~zero.

\section{Contributions}

\textbf{Optimisation of sceptical reasoning}

Sceptical abductive reasoning is an expensive problem from the computational point of view and its bottleneck is the exponential number of candidate explanations which has to be considered. By introducing the minimality constraint, we have reduced the number of candidate explanations generated in the average case, optimising with this the abductive sceptical reasoning process as a whole.

\textbf{Flexibility}

The current framework to generate candidate explanations is a McCulloch Pitts network which is designed to generated the candidate explanations as a static and pre-defined sequence. The replacement of this framework by a recurrent network which is able to learn arbitrary sequences of candidate explanations have given flexibility to our framework. As the sceptical reasoning approach is currently done based on several hypotheses which have not yet been tested, flexibility is crucial characteristic. 

\textbf{Bounded reasoning}

From a cognitive aspect, it is hard to believe that humans generate this large number of candidate explanations in the reasoning process. We believe that they rather generate a subset of these candidate explanations. By introducing the minimality constraint, we have considerably reduced the number of candidate explanations generated in the average case. However, the problem remains the same in the worst case. Moreover, there is still a considerably large number of candidates even after applying minimality. 

Based on this, we believe that a bound is applied when generating candidate explanations and, therefore, we have introduce this feature to our framework. As the network has an anytime behaviour, it remains only to defined what kind of bounds are applied and their characterisation. For this purpose, we need psychological experiments which are beyond the scope of this master thesis. However, the approach in designed in such a way which that it can easily be adapted to the experiments outcome.  

\textbf{Cognitive adequacy}

Throughout the development of this new approach, we have made several hypotheses which raises questions to be answered by means of psychological experiments. These questions have been discussed and an initial setup for experiments to test them has been proposed. Some of the hypotheses make sense from a computational point of view, but as we also want our approach to be cognitively adequate, carrying out these experiments is a crucial step. 

\section{Thesis Structure}

Although we assume the reader to be familiar with logic, logic programming and connectionist networks, Chapter~\ref{sec:preliminaries} introduces some of the general and basic concepts necessary as background knowledge for the work developed. The chapter is divided in two main parts: abduction under the weak completion semantics and connectionist networks. For the first part, we start by introducing some concepts on logic programs such as the weak completion, then we define which semantics we are going to consider throughout the thesis and finally de define the abductive framework as well as its complexity. For the second part, we start by introducing some general concepts of recurrent networks and focus then on Jordan and Elman networks which are going to be used later on.

In Chapter~\ref{sec:cn} we describe an approach based on McCulloch Pitts networks to generate non-complementary candidate explanations for the abductive problem. Later we introduce a possible extension of this approach such that it will now only generate minimal candidates. All the steps necessary for such modification are described by means of an example, but the algorithms on how to generalise to arbitrary problems is also presented.

After introducing the current approach for the generation of candidate explanations, in Chapter~\ref{sec:nn} we propose a new approach which is more flexible. We show that this approach can simulate the same behaviour as the previous one, with the advantage of learning arbitrary sequences of candidates. This is an important feature since we currently make assumptions on the process, but have not yet verified them by means of psychological experiments.

Finally, we want to evaluate the assumptions we have made and, as we already mentioned, a system that aims at being cognitively adequate has to be evaluated with respect to the way humans reason. Therefore, in Chapter~\ref{sec:exp} we suggest to carry out some psychological experiments. From their outcome, we expect to confirm or refute our hypothesis and extract more properties which can further improve our approach. 

